ndates1<- as.Date(HWI$Incident.Date, "%Y%B%d"); ndates1
ndates1<- as.Date(HWI$Incident.Date, "%d%B%Y"); ndates1
HWI$Incident.Date <- ymd(HWI$Incident.Date)
HWI$year <- as.numeric(format(HWI$Incident.Date, "%Y"))
View(HWI)
HWI$Incident.Year <- as.numeric(format(HWI$Incident.Date, "%Y"))
#filter out all the human wildlife interactions
HWI <- animals_involved %>%
filter(Incident.Type %in% c("Human Wildlife Interaction"))
HWI$Incident.Year <- as.numeric(format(HWI$Incident.Date, "%Y"))
View(HWI)
HWI$Incident.Date <- ymd(HWI$Incident.Date)
HWI$Incident.Year <- as.numeric(format(HWI$Incident.Date, "%Y"))
#visualize the number of individuals per region
ggplot(data = HWI, aes(x = Incident.Year, y = Incident.Number)) +
geom_bar(stat = "identity", position = position_dodge()) +
ylab("Frequency") +
xlab("Year") +
theme_bw()
#Where is the first nations area in the HWI data??
incidentcountbyyear <- HWI %>%
count(HWI$Incident.Number)
incidentcount <- HWI %>%
count(HWI$Incident.Number)
incidentcountbyyear <- HWI %>%
count(HWI$Incident.Year)
View(incidentcountbyyear)
#visualize the number of individuals per region
ggplot(data = incidentcountbyyear, aes(x = Incident.Year, y = Count)) +
geom_bar(stat = "identity", position = position_dodge()) +
ylab("Frequency") +
xlab("Year") +
theme_bw()
#visualize the number of individuals per region
ggplot(data = incidentcountbyyear, aes(x = HWI$Incident.Year, y = Count)) +
geom_bar(stat = "identity", position = position_dodge()) +
ylab("Frequency") +
xlab("Year") +
theme_bw()
#visualize the number of individuals per region
ggplot(data = incidentcountbyyear, aes(x = HWI$Incident.Year, y = n)) +
geom_bar(stat = "identity", position = position_dodge()) +
ylab("Frequency") +
xlab("Year") +
theme_bw()
#visualize the number of individuals per region
ggplot(data = incidentcountbyyear, aes(x = HWI$Incident.Year, y = n)) +
ylab("Frequency") +
xlab("Year") +
theme_bw()
View(animals_involved)
# Loading packages ----
options(timeout = max(1000, getOption("timeout")))
library(lattice) # for making graphs
library(faraway) # for calculationg VIF
library(knitr) # for knitting
library(ggplot2) # for scatter plot
library(dplyr) # for pipes
library(formatR) # for formatting for knitting to pdf
library(skimr) # for skimming data
library(tidyverse) #summing
library("lubridate") #convert whole columns to dates
#importing all the datasets to see which ones are useful
#3
coexistence_incidents_record <- read.csv("pca-human-wildlife-coexistence-incidents-detailed-records-2010-2021.csv")
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=80),tidy=TRUE)
# to keep everything inside the page after knitting
knitr::opts_knit$set(root.dir = 'C:/Users/gracelou/OneDrive - UBC/Documents/BIOL440')
#importing all the datasets to see which ones are useful
#3
coexistence_incidents_record <- read.csv("pca-human-wildlife-coexistence-incidents-detailed-records-2010-2021.csv")
#4
animals_involved <- read.csv("pca-human-wildlife-coexistence-animals-involved-detailed-records-2010-2021.csv")
#5
responses <- read.csv("pca-human-wildlife-coexistence-responses-detailed-records-2010-2021.csv")
#6
activites <- read.csv("pca-human-wildlife-coexistence-activities-detailed-records-2010-2021.csv")
#7
incidents_by_incidents_type <- read.csv("pca-human-wildlife-coexistence-incidents-detailed-records-2010-2021.csv")
#8
staff_time_incident <- read.csv("pca-hours-of-staff-time-by-incident-type-2010-2021.csv")
#9
number_incidents_species <- read.csv("pca-number-of-incidents-by-species-2010-2021.csv")
#10
staff_time_species <- read.csv("pca-hours-of-staff-time-by-species-2010-2021.csv")
#11
animals_killed_human_cause <- read.csv("pca-number-of-animals-killed-by-human-causes-2010-2021.csv")
#12
aggressive_encounters_species <- read.csv("pca-number-of-aggressive-encounters-by-species-2010-2021.csv")
#13
animals_invlved_unnatural_attractants <- read.csv("pca-number-of-animals-involved-with-unnatural-attractants-2010-2021.csv")
#14
animals_killed_collisions <-read.csv("pca-number-of-animals-killed-by-collisions-with-vehicles-and-trains-2010-2021.csv")
#15
incidents_by_response <- read.csv("pca-number-of-incidents-by-response-type-2010-2021.csv")
#16
incidents_by_site <- read.csv("pca-number-of-incidents-by-site-2010-2021.csv")
#17
staff_time_site <- read.csv("pca-hours-of-staff-time-by-site-2010-2021.csv")
#18
animals_killed_collisions_site <- read.csv("pca-number-of-animals-killed-by-collisions-with-vehicles-and-trains-by-site-2010-2021.csv")
#19
aggressive_encounters_species_site <- read.csv("pca-number-of-aggressive-encounters-by-species-and-by-site-2010-2021.csv")
#Choosing 4 (animals_involved), 9(number_incidents_species), and 19(aggressive_encounters_species_site).
#filter out all the human wildlife interactions
HWI <- animals_involved %>%
filter(Incident.Type %in% c("Human Wildlife Interaction"))
#visualize the number of individuals per region
ggplot(data = HWI, aes(x = Protected.Heritage.Area, y = Sum.of.Number.of.Animals)) +
geom_bar(stat = "identity", position = position_dodge()) +
ylab("Frequency") +
xlab("Region") +
theme_bw()
unique(HWI$Protected.Heritage.Area)
#Convert dates from characters to date
HWI$Incident.Date <- ymd(HWI$Incident.Date)
# Add a column "Incident Year"
HWI$Incident.Year <- as.numeric(format(HWI$Incident.Date, "%Y"))
incidentcountbyyear <- HWI %>%
count(HWI$Incident.Year)
#incidents increase by year
unique(HWI$Protected.Heritage.Area)
getwd
# Loading packages ----
options(timeout = max(1000, getOption("timeout")))
library(lattice) # for making graphs
library(faraway) # for calculationg VIF
library(knitr) # for knitting
library(ggplot2) # for scatter plot
library(dplyr) # for pipes
library(formatR) # for formatting for knitting to pdf
library(skimr) # for skimming data
library(tidyverse) #summing
library("lubridate") #convert whole columns to dates
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=80),tidy=TRUE)
# to keep everything inside the page after knitting
knitr::opts_knit$set(root.dir = 'C:/Users/gracelou/OneDrive - UBC/Documents/BIOL440')
#importing all the datasets to see which ones are useful
#3
coexistence_incidents_record <- read.csv("pca-human-wildlife-coexistence-incidents-detailed-records-2010-2021.csv")
#4
animals_involved <- read.csv("pca-human-wildlife-coexistence-animals-involved-detailed-records-2010-2021.csv")
#5
responses <- read.csv("pca-human-wildlife-coexistence-responses-detailed-records-2010-2021.csv")
#6
activites <- read.csv("pca-human-wildlife-coexistence-activities-detailed-records-2010-2021.csv")
#7
incidents_by_incidents_type <- read.csv("pca-human-wildlife-coexistence-incidents-detailed-records-2010-2021.csv")
#8
staff_time_incident <- read.csv("pca-hours-of-staff-time-by-incident-type-2010-2021.csv")
#9
number_incidents_species <- read.csv("pca-number-of-incidents-by-species-2010-2021.csv")
#10
staff_time_species <- read.csv("pca-hours-of-staff-time-by-species-2010-2021.csv")
#11
animals_killed_human_cause <- read.csv("pca-number-of-animals-killed-by-human-causes-2010-2021.csv")
#12
aggressive_encounters_species <- read.csv("pca-number-of-aggressive-encounters-by-species-2010-2021.csv")
#13
animals_invlved_unnatural_attractants <- read.csv("pca-number-of-animals-involved-with-unnatural-attractants-2010-2021.csv")
#14
animals_killed_collisions <-read.csv("pca-number-of-animals-killed-by-collisions-with-vehicles-and-trains-2010-2021.csv")
#15
incidents_by_response <- read.csv("pca-number-of-incidents-by-response-type-2010-2021.csv")
#16
incidents_by_site <- read.csv("pca-number-of-incidents-by-site-2010-2021.csv")
#17
staff_time_site <- read.csv("pca-hours-of-staff-time-by-site-2010-2021.csv")
#18
animals_killed_collisions_site <- read.csv("pca-number-of-animals-killed-by-collisions-with-vehicles-and-trains-by-site-2010-2021.csv")
#19
aggressive_encounters_species_site <- read.csv("pca-number-of-aggressive-encounters-by-species-and-by-site-2010-2021.csv")
#Choosing 4 (animals_involved), 9(number_incidents_species), and 19(aggressive_encounters_species_site).
getwd
getwd()
# Loading packages ----
options(timeout = max(1000, getOption("timeout")))
library(lattice) # for making graphs
library(faraway) # for calculationg VIF
library(knitr) # for knitting
library(ggplot2) # for scatter plot
library(dplyr) # for pipes
library(formatR) # for formatting for knitting to pdf
library(skimr) # for skimming data
library(tidyverse) #summing
library("lubridate") #convert whole columns to dates
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=80),tidy=TRUE)
# to keep everything inside the page after knitting
knitr::opts_knit$set(root.dir = 'C:/Users/gracelou/OneDrive - UBC/Documents/BIOL440')
#importing all the datasets to see which ones are useful
#3
coexistence_incidents_record <- read.csv("pca-human-wildlife-coexistence-incidents-detailed-records-2010-2021.csv")
#4
animals_involved <- read.csv("pca-human-wildlife-coexistence-animals-involved-detailed-records-2010-2021.csv")
#5
responses <- read.csv("pca-human-wildlife-coexistence-responses-detailed-records-2010-2021.csv")
#6
activites <- read.csv("pca-human-wildlife-coexistence-activities-detailed-records-2010-2021.csv")
#7
incidents_by_incidents_type <- read.csv("pca-human-wildlife-coexistence-incidents-detailed-records-2010-2021.csv")
#8
staff_time_incident <- read.csv("pca-hours-of-staff-time-by-incident-type-2010-2021.csv")
#9
number_incidents_species <- read.csv("pca-number-of-incidents-by-species-2010-2021.csv")
#10
staff_time_species <- read.csv("pca-hours-of-staff-time-by-species-2010-2021.csv")
#11
animals_killed_human_cause <- read.csv("pca-number-of-animals-killed-by-human-causes-2010-2021.csv")
#12
aggressive_encounters_species <- read.csv("pca-number-of-aggressive-encounters-by-species-2010-2021.csv")
#13
animals_invlved_unnatural_attractants <- read.csv("pca-number-of-animals-involved-with-unnatural-attractants-2010-2021.csv")
#14
animals_killed_collisions <-read.csv("pca-number-of-animals-killed-by-collisions-with-vehicles-and-trains-2010-2021.csv")
#15
incidents_by_response <- read.csv("pca-number-of-incidents-by-response-type-2010-2021.csv")
#16
incidents_by_site <- read.csv("pca-number-of-incidents-by-site-2010-2021.csv")
#17
staff_time_site <- read.csv("pca-hours-of-staff-time-by-site-2010-2021.csv")
#18
animals_killed_collisions_site <- read.csv("pca-number-of-animals-killed-by-collisions-with-vehicles-and-trains-by-site-2010-2021.csv")
#19
aggressive_encounters_species_site <- read.csv("pca-number-of-aggressive-encounters-by-species-and-by-site-2010-2021.csv")
#Choosing 4 (animals_involved), 9(number_incidents_species), and 19(aggressive_encounters_species_site).
#importing all the datasets to see which ones are useful
#3
coexistence_incidents_record <- read.csv("pca-human-wildlife-coexistence-incidents-detailed-records-2010-2021.csv")
#4
animals_involved <- read.csv("pca-human-wildlife-coexistence-animals-involved-detailed-records-2010-2021.csv")
#5
responses <- read.csv("pca-human-wildlife-coexistence-responses-detailed-records-2010-2021.csv")
#6
activites <- read.csv("pca-human-wildlife-coexistence-activities-detailed-records-2010-2021.csv")
#7
incidents_by_incidents_type <- read.csv("pca-human-wildlife-coexistence-incidents-detailed-records-2010-2021.csv")
#8
staff_time_incident <- read.csv("pca-hours-of-staff-time-by-incident-type-2010-2021.csv")
#9
number_incidents_species <- read.csv("pca-number-of-incidents-by-species-2010-2021.csv")
#10
staff_time_species <- read.csv("pca-hours-of-staff-time-by-species-2010-2021.csv")
#11
animals_killed_human_cause <- read.csv("pca-number-of-animals-killed-by-human-causes-2010-2021.csv")
#12
aggressive_encounters_species <- read.csv("pca-number-of-aggressive-encounters-by-species-2010-2021.csv")
#13
animals_invlved_unnatural_attractants <- read.csv("pca-number-of-animals-involved-with-unnatural-attractants-2010-2021.csv")
#14
animals_killed_collisions <-read.csv("pca-number-of-animals-killed-by-collisions-with-vehicles-and-trains-2010-2021.csv")
#15
incidents_by_response <- read.csv("pca-number-of-incidents-by-response-type-2010-2021.csv")
#16
incidents_by_site <- read.csv("pca-number-of-incidents-by-site-2010-2021.csv")
#17
staff_time_site <- read.csv("pca-hours-of-staff-time-by-site-2010-2021.csv")
#18
animals_killed_collisions_site <- read.csv("pca-number-of-animals-killed-by-collisions-with-vehicles-and-trains-by-site-2010-2021.csv")
#19
aggressive_encounters_species_site <- read.csv("pca-number-of-aggressive-encounters-by-species-and-by-site-2010-2021.csv")
#Choosing 4 (animals_involved), 9(number_incidents_species), and 19(aggressive_encounters_species_site).
skim_without_charts("animals-involved")
#filter out all the human wildlife interactions
HWI <- animals_involved %>%
filter(Incident.Type %in% c("Human Wildlife Interaction"))
unique(HWI$Protected.Heritage.Area)
# Loading packages ----
options(timeout = max(1000, getOption("timeout")))
library(lattice) # for making graphs
library(faraway) # for calculationg VIF
library(knitr) # for knitting
library(ggplot2) # for scatter plot
library(dplyr) # for pipes
library(formatR) # for formatting for knitting to pdf
library(skimr) # for skimming data
library(tidyverse) #summing
library("lubridate") #convert whole columns to dates
# Setting root directory ----
knitr::opts_knit$set(root.dir = 'C:/Users/gracelou/OneDrive - UBC/Documents/BIOL440')
#importing all the datasets to see which ones are useful ----
#3
coexistence_incidents_record <- read.csv("pca-human-wildlife-coexistence-incidents-detailed-records-2010-2021.csv")
#importing all the datasets to see which ones are useful ----
#3
coexistence_incidents_record <- read.csv("pca-human-wildlife-coexistence-incidents-detailed-records-2010-2021.csv")
#4
animals_involved <- read.csv("pca-human-wildlife-coexistence-animals-involved-detailed-records-2010-2021.csv")
#5
responses <- read.csv("pca-human-wildlife-coexistence-responses-detailed-records-2010-2021.csv")
# Loading packages ----
options(timeout = max(1000, getOption("timeout")))
library(lattice) # for making graphs
library(faraway) # for calculationg VIF
library(knitr) # for knitting
library(ggplot2) # for scatter plot
library(dplyr) # for pipes
library(formatR) # for formatting for knitting to pdf
library(skimr) # for skimming data
library(tidyverse) #summing
library("lubridate") #convert whole columns to dates
# Setting root directory ----
knitr::opts_knit$set(root.dir = 'C:/Users/gracelou/OneDrive - UBC/Documents/BIOL440')
#importing all the datasets to see which ones are useful ----
#3
coexistence_incidents_record <- read.csv("pca-human-wildlife-coexistence-incidents-detailed-records-2010-2021.csv")
#importing all the datasets to see which ones are useful ----
#3
coexistence_incidents_record <- read.csv("pca-human-wildlife-coexistence-incidents-detailed-records-2010-2021.csv")
#importing all the datasets to see which ones are useful ----
#3
coexistence_incidents_record <- read.csv("pca-human-wildlife-coexistence-incidents-detailed-records-2010-2021.csv")
# Loading packages ----
options(timeout = max(1000, getOption("timeout")))
library(lattice) # for making graphs
library(faraway) # for calculationg VIF
library(knitr) # for knitting
library(ggplot2) # for scatter plot
library(dplyr) # for pipes
library(formatR) # for formatting for knitting to pdf
library(skimr) # for skimming data
library(tidyverse) #summing
library(lubridate) #convert whole columns to dates
#importing all the datasets to see which ones are useful ----
#3
coexistence_incidents_record <- read.csv("data/pca-human-wildlife-coexistence-incidents-detailed-records-2010-2021.csv")
#7
incidents_by_incidents_type <- read.csv("data/pca-human-wildlife-coexistence-incidents-detailed-records-2010-2021.csv")
#8
staff_time_incident <- read.csv("data/pca-hours-of-staff-time-by-incident-type-2010-2021.csv")
#9
number_incidents_species <- read.csv("data/pca-number-of-incidents-by-species-2010-2021.csv")
#10
staff_time_species <- read.csv("data/pca-hours-of-staff-time-by-species-2010-2021.csv")
#11
animals_killed_human_cause <- read.csv("data/pca-number-of-animals-killed-by-human-causes-2010-2021.csv")
#12
aggressive_encounters_species <- read.csv("data/pca-number-of-aggressive-encounters-by-species-2010-2021.csv")
#13
animals_invlved_unnatural_attractants <- read.csv("data/pca-number-of-animals-involved-with-unnatural-attractants-2010-2021.csv")
#14
animals_killed_collisions <-read.csv("data/pca-number-of-animals-killed-by-collisions-with-vehicles-and-trains-2010-2021.csv")
#15
incidents_by_response <- read.csv("data/pca-number-of-incidents-by-response-type-2010-2021.csv")
#16
incidents_by_site <- read.csv("data/pca-number-of-incidents-by-site-2010-2021.csv")
#17
staff_time_site <- read.csv("data/pca-hours-of-staff-time-by-site-2010-2021.csv")
#18
animals_killed_collisions_site <- read.csv("data/pca-number-of-animals-killed-by-collisions-with-vehicles-and-trains-by-site-2010-2021.csv")
#19
aggressive_encounters_species_site <- read.csv("data/pca-number-of-aggressive-encounters-by-species-and-by-site-2010-2021.csv")
#Skim animals involved data ----
skim_without_charts("animals-involved")
#filter out all the human wildlife interactions ----
HWI <- animals_involved %>%
filter(Incident.Type %in% c("Human Wildlife Interaction"))
#visualize the number of individuals per species ----
ggplot(data = HWI, aes(x = Species.Common.Name, y = Sum.of.Number.of.Animals)) +
geom_bar(stat = "identity", position = position_dodge()) +
ylab("Frequency") +
xlab("Species") +
theme_bw()
#Cleaning the first nations heritage site in HWI data ----
HWI$Protected.Heritage.Area[HWI$Protected.Heritage.Area == "Saoy\xfa-?ehdacho National Historic Site of Canada"]<- "Grizzly Bear Mountain and Scented Grass Hills"
#visualize the number of individuals per region ----
ggplot(data = HWI, aes(x = Protected.Heritage.Area, y = Sum.of.Number.of.Animals)) +
geom_bar(stat = "identity", position = position_dodge()) +
ylab("Frequency") +
xlab("Region") +
theme_bw()
# count the number of regions and the number of species in HWI ----
regioncount <- HWI %>%
count(HWI$Protected.Heritage.Area)
speciescount <- HWI %>%
count(HWI$Species.Common.Name)
# count the number of regions with aggressive encounters ----
aggressive_regioncount <- aggressive_encounters_species_site %>%
count(aggressive_encounters_species_site$Protected.Heritage.Area)
# count the number of each species engaged in aggressive encounters ----
aggressive_speciescount <- aggressive_encounters_species_site %>%
count(aggressive_encounters_species_site$Species.Common.Name)
# Convert dates in HWI from characters to date ----
HWI$Incident.Date <- ymd(HWI$Incident.Date)
# Add a column "Incident Year" to HWI ----
HWI$Incident.Year <- as.numeric(format(HWI$Incident.Date, "%Y"))
# Count incident by year in HWI ----
incidentcountbyyear <- HWI %>%
count(HWI$Incident.Year)
#filter out all the human wildlife interactions ----
HWI <- animals_involved %>%
filter(Incident.Type %in% c("Human Wildlife Interaction"))
#importing all the datasets to see which ones are useful ----
#3
coexistence_incidents_record <- read.csv("data/pca-human-wildlife-coexistence-incidents-detailed-records-2010-2021.csv")
Parkpolygon<-readOGR("data/Reserves_of_Canada_Legislative_Boundaries.shp")
library(rgdal)
Parkpolygon<-readOGR("data/Reserves_of_Canada_Legislative_Boundaries.shp")
shape <- read_sf(dsn = "data/Reserves_of_Canada_Legislative_Boundaries.shp", layer = "SHAPEFILE")
library(lattice) # for making graphs
library(knitr) # for knitting
library(ggplot2) # for scatter plot
library(dplyr) # for pipes
library(skimr) # for skimming data
library(tidyverse) #summing
library(lubridate) #convert whole columns to dates
library(zoo) #dates as year month
library(canadianmaps) #import annotated map of Canada
library(sf) # spatial data
library(sp) #Spatial Points function
library(rstudioapi) #for creating colour palette
library(grDevices) #for creating colour palette
library(fBasics) #for creating colour palette
library(mgcv) #gam
library(terra) #shape file
# importing shape files of Canadian national parks
terra::vect("data/Reserves_of_Canada_Legislative_Boundaries.shp")
vect("data/Reserves_of_Canada_Legislative_Boundaries.shp")
shape <- read_sf(dsn = "data/Reserves_of_Canada_Legislative_Boundaries.shp", layer = "SHAPEFILE")
st_read("data/Reserves_of_Canada_Legislative_Boundaries.shp")
library(rgdal)
# importing shape files of Canadian national parks
terra::vect("data/Reserves_of_Canada_Legislative_Boundaries.shp")
# importing shape files of Canadian national parks
terra::vect("data/Parkpolygon")
parkpolygon <- system.file("data/Reserves_of_Canada_Legislative_Boundaries", package="terra")
terra::vect(f)
plot(parkpolygon)
ggplot() +
geom_polygon(data = parkpolygon, aes( x = long, y = lat, group = group), fill="#69b3a2", color="white") +
theme_void()
parkpolygon <- system.file("data/Reserves_of_Canada_Legislative_Boundaries", package="terra")
terra::vect(f)
# importing shape files of Canadian national parks
terra::vect("data/Reserves_of_Canada_Legislative_Boundaries.shp")
st_read("data/Reserves_of_Canada_Legislative_Boundaries.shp")
shape <- read_sf(dsn = "data/Reserves_of_Canada_Legislative_Boundaries.shp", layer = "SHAPEFILE")
# importing shape files of Canadian national parks
terra::vect("data/Reserves_of_Canada_Legislative_Boundaries.shp")
Parkpolygon<-readOGR("data/Reserves_of_Canada_Legislative_Boundaries.shp")
library("xml2")
library("rvest")
library("dplyr")
library("terra")
#extract all links for 2010 [done] ----
url <- "https://www.ncei.noaa.gov/data/land-normalized-difference-vegetation-index/access/2010/"
pg <- read_html(url)
linkys <- html_attr(html_nodes(pg, "a"), "href")
LINKS <- list()
for(i in 1:length(linkys)){
link <- paste(url, linkys[i], sep = "")
LINKS[i] <- link
}
LINKS <- do.call(rbind, LINKS)
# redownload all the links and now it should work
for(j in 6:length(linkys)){
url_path <- paste(url, linkys[j], sep = "")
path <- paste("C:/Users/grace/Documents/GitHub/HWI_parks/2010ndvi/",linkys[j], sep="")
try(download.file(url_path, destfile = path, mode = "wb")) #add mode = wb and now it works --> the probably won't have to run corrupt file unless things don't work
Sys.sleep(5)
}
# Loading packages ----
options(timeout = max(1000, getOption("timeout")))
library(lattice) # for making graphs
library(knitr) # for knitting
library(ggplot2) # for scatter plot
library(dplyr) # for pipes
library(skimr) # for skimming data
library(tidyverse) #summing
library(lubridate) #convert whole columns to dates
library(zoo) #dates as year month
library(canadianmaps) #import annotated map of Canada
library(sf) # spatial data
library(sp) #Spatial Points function
library(rstudioapi) #for creating colour palette
library(grDevices) #for creating colour palette
library(fBasics) #for creating colour palette
library(mgcv) #gam
library(terra) #shape file
# set working directory
setwd("C:/Users/grace/Documents/GitHub/HWI_parks")
ABpolygon <- st_read("data/CLAB_AB_2023-09-08/CLAB_AB_2023-09-08.shp")
plot(ABpolygon)
BCpolygon <- st_read("data/CLAB_BC_2023-09-08/CLAB_BC_2023-09-08.shp")
plot(BCpolygon)
MBpolygon <- st_read("data/CLAB_MB_2023-09-08/CLAB_MB_2023-09-08.shp")
plot(MBpolygon)
NBpolygon <- st_read("data/CLAB_NB_2023-09-08/CLAB_NB_2023-09-08.shp")
plot(NBpolygon)
NLpolygon <- st_read("data/CLAB_NL_2023-09-08/CLAB_NL_2023-09-08.shp")
plot(NLpolygon)
NSpolygon <- st_read("data/CLAB_NS_2023-09-08/CLAB_NS_2023-09-08.shp")
plot(NSpolygon)
NTpolygon <- st_read("data/CLAB_NT_2023-09-08/CLAB_NT_2023-09-08.shp")
plot(NTpolygon)
NUpolygon <- st_read("data/CLAB_NU_2023-09-08/CLAB_NU_2023-09-08.shp")
plot(NUpolygon)
ONpolygon <- st_read("data/CLAB_ON_2023-09-08/CLAB_ON_2023-09-08.shp")
plot(ONpolygon)
PEpolygon <- st_read("data/CLAB_PE_2023-09-08/CLAB_PE_2023-09-08.shp")
plot(PEpolygon)
QCpolygon <- st_read("data/CLAB_QC_2023-09-08/CLAB_QC_2023-09-08.shp")
plot(QCpolygon)
SKpolygon <- st_read("data/CLAB_SK_2023-09-08/CLAB_SK_2023-09-08.shp")
plot(SKpolygon)
YTpolygon <- st_read("data/CLAB_YT_2023-09-08/CLAB_YT_2023-09-08.shp")
plot(YTpolygon)
waterton_lakes <- ABpolygon[ABpolygon$CLAB_ID == "WATE", ]
plot(waterton_lakes)
saveRDS(waterton_lakes,file ="rds/waterton_lakes.rds")
